
import base64
import streamlit as st 
from langchain_huggingface.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores.faiss import FAISS
from langchain.embeddings import CacheBackedEmbeddings
from langchain.storage import LocalFileStore
from langchain.chains import RetrievalQA, LLMChain
from langchain.chains.combine_documents.stuff import StuffDocumentsChain
from langchain.prompts import PromptTemplate
from langchain_community.chat_models import ChatOpenAI  
import os
import time
from langchain_community.chat_models import ChatOllama  


# Set page config
st.set_page_config(page_title="Legal Assistant", page_icon="‚öñÔ∏è", layout="wide")

# Custom CSS
st.markdown("""
    <style>
    .stApp {
        background-color: #f0f8ff;
    }
    .big-font {
        font-size:20px !important;
        font-weight: bold;
    }
    .stButton>button {
        background-color: #4682B4;
        color: white;
    }
    .stTextInput>div>div>input {
        background-color: #E6F3FF;
    }
    </style>
    """, unsafe_allow_html=True)

hide_st_style = """
            <style>
            #MainMenu {visibility: hidden;}
            footer {visibility: hidden;}
            header {visibility: hidden;}
            </style>
            """
st.markdown(hide_st_style, unsafe_allow_html=True)

# Title and description
st.title("üèõÔ∏è Advanced Legal Assistant for Women and Children")
st.markdown("Welcome to your AI-powered legal research companion. Ask any legal question, and get comprehensive answers backed by relevant case law.")

# Initialize Hugging Face embeddings model
@st.cache_resource
def load_embeddings():
    return HuggingFaceEmbeddings()

core_embeddings_model = load_embeddings()

@st.cache_resource
def load_vector_db():
    return FAISS.load_local("INDEX", core_embeddings_model,allow_dangerous_deserialization=True)

vector_db = load_vector_db()

# Define the prompt template for the LLM
prompt_template ="""

{question}
---
1. Legal Principle:

- **Insert Legal Principle Title Here:**  
  Provide a brief, clear description of the main legal rule, doctrine, or statute that applies to the lawyer's question. This section should explain the foundational legal principles underpinning the issue at hand, including key elements of the rule or doctrine.
---
2. Case Reference:
- **Case Name:** ***Insert Case Name Here***  
- **Citation:** *Insert Full Legal Citation Here*  
- **Hyperlink to Case:** [Provide Hyperlink to the Case for Reference]  

- **Relevance:**  
  Explain why this case is relevant to the question being asked. How does the case support or illustrate the legal principle discussed? Select a case directly applicable to the lawyer's jurisdiction if possible, and provide a brief explanation of its importance in this legal context.
---
3. Implications:
- Discuss the broader significance of the legal principle in the context of the law. What does this principle mean for current and future legal cases? How does it affect the legal landscape? Consider the practical implications for both the current case and similar cases going forward. 
  Include potential consequences, precedents set by the principle, or conflicts with other areas of law.
---
4. Court Decision:
- **Court's Ruling:**  
  Summarize the court‚Äôs ruling in the cited case, emphasizing how the court applied the legal principle to the specific facts of the case. 
  Focus on the key reasoning or interpretations made by the court that are pertinent to the lawyer‚Äôs query.
- **Key Reasoning:**  
  Highlight any significant legal interpretations, doctrines, or principles that the court relied on when reaching its decision. 
  This should connect back to the lawyer‚Äôs question and provide practical insights into how the legal principle is applied.
---
5. Summary:
- Provide a concise overall summary that integrates the legal principle, case reference, implications, and court decision.
  This section should distill the information into a clear and actionable insight that directly addresses the lawyer's question. Ensure that the summary provides a practical takeaway for the lawyer‚Äôs case preparation or strategy.
---
6. Source:
- Provide the source(s) from which the legal information was retrieved (e.g., legal database, case law citation, statutory references). Include any valid hyperlinks for further reference.
{context}
"""
api_key=st.secrets["OPENAI_API_KEY"]
# Initialize the language model (ChatOpenAI)
@st.cache_resource
def load_llm():
    return ChatOpenAI(model="gpt-4o-mini", api_key=api_key)

llm = load_llm()

# Create a retriever from the vector store
retriever = vector_db.as_retriever()

# Set up prompt template for LLM chain
QA_CHAIN_PROMPT = PromptTemplate.from_template(prompt_template)
llm_chain = LLMChain(llm=llm, prompt=QA_CHAIN_PROMPT)

# Document combination chain setup
document_prompt = PromptTemplate(
    input_variables=["page_content", "source"],
    template="Context:\ncontent:{page_content}\nsource:{source}",
)
combine_documents_chain = StuffDocumentsChain(
    llm_chain=llm_chain,
    document_variable_name="context",
    document_prompt=document_prompt,
)

# Set up RetrievalQA chain
qa = RetrievalQA(
    combine_documents_chain=combine_documents_chain,
    retriever=retriever,
    return_source_documents=True,
)

# User input
user_input = st.text_input("Enter your legal question:", placeholder="e.g., What are the key elements of a valid contract?")

# Process button
if st.button("Get Legal Insights"):
    if user_input:
        with st.spinner("Analyzing your question..."):
            start_time = time.time()
            try:
                # Invoke the retriever with the user query
                response = qa.invoke({"query": user_input})
                
                # Display response
                st.markdown("### Legal Analysis", unsafe_allow_html=True)
                st.markdown(response["result"], unsafe_allow_html=True)
                
                # Display processing time
                st.info(f"Processing time: {time.time() - start_time:.2f} seconds")
                
                # Display sources
                st.markdown("### Sources", unsafe_allow_html=True)
                unique_sources = set()
                top_n = 3  # Set how many top documents to print
                unique_sources = set()  # Track unique sources
                document_count = 0
                result_sources = []  # List to store the sources

                # base_url = r"C:\Users\aipro\Documents\Fw_ Meeting with Promptora AI\Laws"

                for doc in response['source_documents']:
                    source = doc.metadata['source']
                    
                    if source not in unique_sources:
                        unique_sources.add(source)
                        document_count += 1
                        
                        # Extract just the filename without the path
                        filename = os.path.basename(source)
                        
                        # Replace .txt with .pdf
                        filename = filename.replace('.txt', '.pdf')
                        
                        # Create a hyperlink with "click here" text
                        result_sources.append(f"[{filename}]")
                        
                        if document_count == top_n:
                            break

                # Join the sources into a newline-separated string
                # result_source_string = "\n\n".join(result_sources)
                # print(result_source_string)
                # st.markdown(f"result:{result_source_string}",unsafe_allow_html=True)
                            
            except Exception as e:
                st.error(f"An error occurred: {str(e)}")
    else:
        st.warning("Please enter a question before submitting.")

